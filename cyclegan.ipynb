{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cyclegan",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzKu5vjRJ6gt",
        "colab_type": "code",
        "outputId": "0f57d1ca-39d5-42c4-e587-8b691ca0d716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-ld65slcs\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-ld65slcs\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101065 sha256=967e606aa3687d1962d698c14bc0f06343785bb0297ef089da88c09fb2bfcb01\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oh1mhnw_/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AuX-2TuNG6o",
        "colab_type": "code",
        "outputId": "3ed2093f-681b-4d71-bf61-260f6b2d4ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import LeakyReLU, Dropout, Activation, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Conv2DTranspose\n",
        "import cv2\n",
        "import re\n",
        "import datetime\n",
        "import skimage\n",
        "import scipy # \n",
        "import keras_contrib\n",
        "from glob import glob\n",
        "from IPython.display import Image\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from random import random\n",
        "\n",
        "from keras.initializers import RandomNormal\n",
        "\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZwep2FNYE4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, img_res=(256, 256)):\n",
        "        self.img_res = img_res\n",
        "        _URL = 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz'\n",
        "\n",
        "        path_to_zip = tf.keras.utils.get_file('facades.tar.gz',origin=_URL,extract=True)\n",
        "\n",
        "        self.PATH = os.path.join(os.path.dirname(path_to_zip), 'facades/')\n",
        "\n",
        "    \n",
        "    def load_data(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"test\"\n",
        "        path=os.path.join(self.PATH,'train') if not is_testing else os.path.join(self.PATH,'test')\n",
        "        train_path = glob('%s/*.jpg' %(path))\n",
        "#         label_path = glob('%s/*.png' %(data_path))\n",
        "        batch_images = np.random.choice(train_path, size=batch_size)\n",
        "\n",
        "\n",
        "        imgs_A = []\n",
        "        imgs_B = []\n",
        "        for img_path in batch_images:\n",
        "            img = img_A = cv2.imread(img_path).astype(np.float)\n",
        "\n",
        "            h, w, _ = img.shape\n",
        "            _w = int(w/2)\n",
        "            img_A, img_B = img[:, :_w, :], img[:, _w:, :]\n",
        "#             h, w, _ = img.shape\n",
        "#             _w = int(w/2)\n",
        "#             img_A, img_B = img[:, :_w, :], img[:, _w:, :]\n",
        "\n",
        "            img_A = cv2.resize(img_A, self.img_res)\n",
        "            img_B = cv2.resize(img_B, self.img_res)\n",
        "\n",
        "            # If training => do random flip\n",
        "            imgs_A.append(img_A)\n",
        "            imgs_B.append(img_B)\n",
        "\n",
        "        imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "        imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "        return imgs_A, imgs_B\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        data_path=os.path.join(self.PATH,'train')\n",
        "        train_path = glob('%s/*.jpg' %(data_path))\n",
        "\n",
        "        self.n_batches = int(len(train_path) / batch_size)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch = train_path[i*batch_size:(i+1)*batch_size]\n",
        "            imgs_A, imgs_B = [], []\n",
        "            for img in batch:\n",
        "                img = img_A = cv2.imread(img).astype(np.float)\n",
        "\n",
        "                h, w, _ = img.shape\n",
        "                _w = int(w/2)\n",
        "                img_A, img_B = img[:, :_w, :], img[:, _w:, :]\n",
        "\n",
        "                img_A = cv2.resize(img_A, self.img_res)\n",
        "                img_B = cv2.resize(img_B, self.img_res)\n",
        "                imgs_A.append(img_A)\n",
        "                imgs_B.append(img_B)\n",
        "\n",
        "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "            yield imgs_A, imgs_B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idc6X3DfX9FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cygan():\n",
        "    def __init__(self, lambda_val):\n",
        "        #input shape\n",
        "        self.img_rows = 256\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows,self.img_rows,self.channels)\n",
        "        self.resnet_block_num = 9\n",
        "        self.batch_size=1\n",
        "        self.losses = [[]]\n",
        "        #output of PatchGAN\n",
        "        patch = int(self.img_rows / 2**4)\n",
        "        self.disc_patch = (patch, patch, 1)\n",
        "        \n",
        "        #data loader\n",
        "        self.loader = DataLoader()\n",
        "\n",
        "        #lossweights\n",
        "        self.lambda_cycleloss = lambda_val\n",
        "        self.lamba_idloss = 0.1*self.lambda_cycleloss\n",
        "        \n",
        "        #optimizer\n",
        "        opti = Adam(0.0002,0.5)\n",
        "        \n",
        "        #building and compiling the discriminators\n",
        "        self.d_1 = self.discriminator()\n",
        "        self.d_1.compile(loss = 'mse',optimizer = opti,metrics = ['accuracy'])\n",
        "        self.d_2 = self.discriminator()\n",
        "        self.d_2.compile(loss = 'mse',optimizer = opti,metrics = ['accuracy'])\n",
        "        #building the generators\n",
        "        self.g_1 = self.generator()\n",
        "        self.g_2 = self.generator()\n",
        "        #input image\n",
        "        img_A = Input(shape=self.img_shape)\n",
        "        img_B = Input(shape=self.img_shape)\n",
        "        \n",
        "        fake_B = self.g_1(img_A)\n",
        "        cycle_A = self.g_2(fake_B)\n",
        "        fake_A = self.g_2(img_B)\n",
        "        cycle_B = self.g_1(fake_A)\n",
        "        self.d_1.trainable = False\n",
        "        self.d_2.trainable = False\n",
        "        \n",
        "        valid_A = self.d_2(fake_A)\n",
        "        valid_B = self.d_1(fake_B)\n",
        "        \n",
        "        self.combined = Model([img_A,img_B],[valid_A,valid_B,cycle_A,cycle_B])\n",
        "        self.combined.compile(loss=['mse','mse','mae','mae'],loss_weights=[1,1,self.lambda_cycleloss,self.lambda_cycleloss],optimizer = opti)\n",
        "    \n",
        "    #defining the generator with three components - encoder, resnet block, decoder\n",
        "    def generator(self):\n",
        "        \n",
        "        def resnet_block(kernel, input_layer):\n",
        "            init = RandomNormal(stddev=0.02)\n",
        "            model = Conv2D(kernel, kernel_size=(3,3),padding='same',kernel_initializer=init)(input_layer)\n",
        "            model = InstanceNormalization(axis=-1)(model)\n",
        "            model = Activation('relu')(model)\n",
        "            model = Conv2D(kernel, kernel_size=(3,3),padding='same',kernel_initializer=init)(model)\n",
        "            model = InstanceNormalization(axis=-1)(model)\n",
        "            model = Concatenate()([model,input_layer])\n",
        "            return model    \n",
        "\n",
        "        \n",
        "        #c7s1-64\n",
        "        init = RandomNormal(stddev=0.02)\n",
        "        input_layer = Input(shape = self.img_shape)\n",
        "        model = Conv2D(64, kernel_size=(7,7),strides=(1,1),padding='same',kernel_initializer=init)(input_layer)\n",
        "        model = InstanceNormalization(axis=-1)(model)\n",
        "        model = Activation('relu')(model)\n",
        "        #d128\n",
        "        model = Conv2D(128, kernel_size=(3,3),strides=(2,2),padding='same',kernel_initializer=init)(model)\n",
        "        model = InstanceNormalization(axis=-1)(model)\n",
        "        model = Activation('relu')(model)\n",
        "        #d256\n",
        "        model = Conv2D(256, kernel_size=(3,3),strides=(2,2),padding='same',kernel_initializer=init)(model)\n",
        "        model = InstanceNormalization(axis=-1)(model)\n",
        "        model = Activation('relu')(model)\n",
        "        #R256\n",
        "        for resnet in range(self.resnet_block_num):\n",
        "            model = resnet_block(256,model)\n",
        "        #u128\n",
        "        model = Conv2DTranspose(128, kernel_size=(3,3),strides=(2,2),padding='same',kernel_initializer=init)(model)\n",
        "        model = InstanceNormalization(axis=-1)(model)\n",
        "        model = Activation('relu')(model)\n",
        "        #u64\n",
        "        model = Conv2DTranspose(64, kernel_size=(3,3),strides=(2,2),padding='same',kernel_initializer=init)(model)\n",
        "        model = InstanceNormalization(axis=-1)(model)\n",
        "        model = Activation('relu')(model)\n",
        "        #c7s1-3\n",
        "        model = Conv2D(3, kernel_size=(7,7),strides=(1,1),padding='same',kernel_initializer=init)(model)\n",
        "        model = InstanceNormalization(axis=-1)(model)\n",
        "        out_img = Activation('relu')(model)\n",
        "\n",
        "        return Model(input_layer,out_img)\n",
        "    \n",
        "    #discriminator is Patch GAN architecture same as Pix2Pix\n",
        "    def discriminator(self):\n",
        "        init = RandomNormal(mean=0.0, stddev=0.02, seed=123)\n",
        "\n",
        "        def single_layer(input_img, filters, filter_size = 4, batch_norm = True, kern_init = init):\n",
        "            \"\"\"layer in the discriminator\"\"\"\n",
        "            model = Conv2D(filters, filter_size,strides = 2,padding ='same',kernel_initializer=kern_init)(input_img)\n",
        "            if batch_norm:\n",
        "                model = InstanceNormalization(axis=-1)(model)\n",
        "            model = LeakyReLU(alpha=0.2)(model)\n",
        "            return model\n",
        "\n",
        "        i = Input(shape = self.img_shape)\n",
        "\n",
        "    #         Concatenating image and label image\n",
        "\n",
        "\n",
        "        l1 = single_layer(i,64,batch_norm = False)\n",
        "        l2 = single_layer(l1,128,)\n",
        "        l3 = single_layer(l2,256)\n",
        "        l4 = single_layer(l3,512)\n",
        "\n",
        "        l5 = Conv2D(1,(4,4),strides = 1,padding = 'same',activation = 'sigmoid')(l4)\n",
        "        return Model(i,l5)\n",
        "\n",
        "    \n",
        "    def train(self,epochs = 100,batch_size = 1, sample_interval = 50):\n",
        "        \n",
        "        start_time = datetime.datetime.now()\n",
        "        valid=np.ones((batch_size,)+self.disc_patch)\n",
        "        fake=np.zeros((batch_size,)+self.disc_patch)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "    #         start=time.time()\n",
        "            for batch_i, (imgA,imgB) in enumerate(self.loader.load_batch(batch_size)):\n",
        "                fakeA = self.g_2.predict(imgB)\n",
        "                fakeB = self.g_1.predict(imgA)\n",
        "                \n",
        "                d_1_real_loss = self.d_1.train_on_batch(imgB,valid)\n",
        "                d_1_fake_loss = self.d_1.train_on_batch(fakeB,fake)\n",
        "                d_1_loss = 0.5 *np.add(d_1_real_loss,d_1_fake_loss)\n",
        "                \n",
        "                d_2_real_loss = self.d_2.train_on_batch(imgA,valid)\n",
        "                d_2_fake_loss = self.d_2.train_on_batch(fakeA,fake)\n",
        "                d_2_loss = 0.5 *np.add(d_2_real_loss,d_2_fake_loss)\n",
        "                \n",
        "                d_total_loss = 0.5*np.add(d_1_loss,d_2_loss)\n",
        "                \n",
        "                g_loss = self.combined.train_on_batch([imgA, imgB], [valid,valid, imgA,imgB])\n",
        "                elapsed_time = datetime.datetime.now()-start_time\n",
        "                print(\"Epoch - %d, Batch - %d, D_loss %f acc %3d%%, (G_loss %f, adv_loss %f, cycle_loss %f) , time %s\" %(epoch,batch_i, d_total_loss[0], d_total_loss[1]*100, g_loss[0],np.mean(g_loss[1:3]),np.mean(g_loss[3:5]),elapsed_time))\n",
        "                if batch_i % sample_interval == 0:\n",
        "                    self.sample_images(epoch, batch_i)\n",
        "                if batch_i == self.loader.n_batches-1:\n",
        "                    self.losses.append((d_total_loss,g_loss))\n",
        "                \n",
        "#         save_models(epoch)\n",
        "        \n",
        "    def sample_images(self, epoch, batch_i):\n",
        "        os.makedirs('cycleganimages/', exist_ok=True)\n",
        "        r, c = 2, 3\n",
        "\n",
        "        imgs_A, imgs_B = self.loader.load_data(batch_size=1, is_testing=True)\n",
        "        fake_A = self.g_2.predict(imgs_B)\n",
        "        fake_B = self.g_1.predict(imgs_A)\n",
        "        cycle_A = self.g_2.predict(fake_B)\n",
        "        cycle_B = self.g_1.predict(fake_A)\n",
        "        gen_imgs = np.concatenate([imgs_B, fake_A,cycle_B, imgs_A,fake_B,cycle_A])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Translated', 'Reconstructed']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"cycleganimages/lambda_%d_%d_%d.png\" % (self.lambda_cycleloss,epoch, batch_i))\n",
        "        plt.close()\n",
        "        \n",
        "#     def save_models(self,epoch):\n",
        "#         filename1 = 'g_model_AtoB_%06d.h5' % (epoch+1)\n",
        "#         self.g_1.save(filename1)\n",
        "#         # save the second generator model\n",
        "#         filename2 = 'g_model_BtoA_%06d.h5' % (epoch+1)\n",
        "#         self.g_2.save(filename2)\n",
        "#         print('>Saved: %s and %s' % (filename1, filename2))\n",
        "    \n",
        "    def show_losses(self):\n",
        "        losses = np.array(self.losses)\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        plt.plot(losses[0], label='Discriminator')\n",
        "        plt.plot(losses[1], label='Generator')\n",
        "        plt.title(\"Training Losses\")\n",
        "        plt.legend()\n",
        "        fig.savefig(\"cycleganimages/lambda_%d_Loss.png\" %(self.lambda_cycleloss))\n",
        "        \n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Ei9jnQTwrql",
        "colab": {}
      },
      "source": [
        "cycleGAN = cygan(10)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6WBUkpT8RBX",
        "colab_type": "code",
        "outputId": "7f5b9aad-6243-40f7-a93b-052fc54520d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "cycleGAN.train(epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 9, Batch - 85, D_loss 0.000001 acc 100%, (G_loss 9.153187, adv_loss 0.998663, cycle_loss 0.357793) , time 1:14:02.048228\n",
            "Epoch - 9, Batch - 86, D_loss 0.000000 acc 100%, (G_loss 11.761122, adv_loss 0.998782, cycle_loss 0.488178) , time 1:14:03.241573\n",
            "Epoch - 9, Batch - 87, D_loss 0.000001 acc 100%, (G_loss 9.011677, adv_loss 0.998674, cycle_loss 0.350716) , time 1:14:04.416233\n",
            "Epoch - 9, Batch - 88, D_loss 0.000001 acc 100%, (G_loss 8.749843, adv_loss 0.998660, cycle_loss 0.337626) , time 1:14:05.610720\n",
            "Epoch - 9, Batch - 89, D_loss 0.000001 acc 100%, (G_loss 10.542496, adv_loss 0.998555, cycle_loss 0.427269) , time 1:14:06.782676\n",
            "Epoch - 9, Batch - 90, D_loss 0.000001 acc 100%, (G_loss 8.974468, adv_loss 0.998707, cycle_loss 0.348853) , time 1:14:07.978893\n",
            "Epoch - 9, Batch - 91, D_loss 0.000001 acc 100%, (G_loss 9.542013, adv_loss 0.998461, cycle_loss 0.377255) , time 1:14:09.162091\n",
            "Epoch - 9, Batch - 92, D_loss 0.000001 acc 100%, (G_loss 11.700485, adv_loss 0.998633, cycle_loss 0.485161) , time 1:14:10.333737\n",
            "Epoch - 9, Batch - 93, D_loss 0.000001 acc 100%, (G_loss 9.764385, adv_loss 0.998647, cycle_loss 0.388355) , time 1:14:11.520122\n",
            "Epoch - 9, Batch - 94, D_loss 0.000001 acc 100%, (G_loss 9.315786, adv_loss 0.998373, cycle_loss 0.365952) , time 1:14:12.710612\n",
            "Epoch - 9, Batch - 95, D_loss 0.000001 acc 100%, (G_loss 10.299934, adv_loss 0.998197, cycle_loss 0.415177) , time 1:14:13.892351\n",
            "Epoch - 9, Batch - 96, D_loss 0.000001 acc 100%, (G_loss 9.252986, adv_loss 0.998659, cycle_loss 0.362783) , time 1:14:15.081394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv__Zht56RD4",
        "colab_type": "code",
        "outputId": "01f5caa9-fc09-484d-85bf-7a8e2a6178da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cycleGAN1 = cygan(5)\n",
        "cycleGAN1.train(epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz\n",
            "30171136/30168306 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch - 0, Batch - 0, D_loss 0.339980 acc  40%, (G_loss 9.367560, adv_loss 0.357778, cycle_loss 0.865200) , time 0:02:16.472606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch - 0, Batch - 1, D_loss 0.313731 acc  51%, (G_loss 8.081037, adv_loss 0.450031, cycle_loss 0.718097) , time 0:04:04.110098\n",
            "Epoch - 0, Batch - 2, D_loss 0.290096 acc  60%, (G_loss 7.891266, adv_loss 0.547147, cycle_loss 0.679697) , time 0:05:30.314356\n",
            "Epoch - 0, Batch - 3, D_loss 0.268774 acc  63%, (G_loss 7.544127, adv_loss 0.516394, cycle_loss 0.651134) , time 0:06:56.934067\n",
            "Epoch - 0, Batch - 4, D_loss 0.271707 acc  65%, (G_loss 6.438654, adv_loss 0.543671, cycle_loss 0.535131) , time 0:08:22.839527\n",
            "Epoch - 0, Batch - 5, D_loss 0.245146 acc  67%, (G_loss 6.596380, adv_loss 0.580499, cycle_loss 0.543538) , time 0:09:48.352925\n",
            "Epoch - 0, Batch - 6, D_loss 0.249146 acc  68%, (G_loss 6.135725, adv_loss 0.525263, cycle_loss 0.508520) , time 0:11:14.113446\n",
            "Epoch - 0, Batch - 7, D_loss 0.233806 acc  70%, (G_loss 7.470408, adv_loss 0.576382, cycle_loss 0.631764) , time 0:12:40.349846\n",
            "Epoch - 0, Batch - 8, D_loss 0.244009 acc  69%, (G_loss 6.515527, adv_loss 0.590653, cycle_loss 0.533422) , time 0:14:06.376488\n",
            "Epoch - 0, Batch - 9, D_loss 0.228215 acc  71%, (G_loss 5.611488, adv_loss 0.607580, cycle_loss 0.439633) , time 0:15:31.976169\n",
            "Epoch - 0, Batch - 10, D_loss 0.253500 acc  67%, (G_loss 6.948489, adv_loss 0.521680, cycle_loss 0.590513) , time 0:16:57.984417\n",
            "Epoch - 0, Batch - 11, D_loss 0.238425 acc  70%, (G_loss 6.633339, adv_loss 0.622503, cycle_loss 0.538833) , time 0:18:23.384231\n",
            "Epoch - 0, Batch - 12, D_loss 0.254228 acc  70%, (G_loss 5.970031, adv_loss 0.507506, cycle_loss 0.495502) , time 0:19:48.476562\n",
            "Epoch - 0, Batch - 13, D_loss 0.183900 acc  77%, (G_loss 6.189688, adv_loss 0.561114, cycle_loss 0.506746) , time 0:21:14.082439\n",
            "Epoch - 0, Batch - 14, D_loss 0.275575 acc  61%, (G_loss 6.715785, adv_loss 0.517239, cycle_loss 0.568131) , time 0:22:39.511953\n",
            "Epoch - 0, Batch - 15, D_loss 0.242163 acc  73%, (G_loss 5.406483, adv_loss 0.482551, cycle_loss 0.444138) , time 0:24:05.292513\n",
            "Epoch - 0, Batch - 16, D_loss 0.329983 acc  58%, (G_loss 5.220385, adv_loss 0.452353, cycle_loss 0.431568) , time 0:25:30.693979\n",
            "Epoch - 0, Batch - 17, D_loss 0.272803 acc  66%, (G_loss 6.683712, adv_loss 0.519496, cycle_loss 0.564472) , time 0:26:56.820011\n",
            "Epoch - 0, Batch - 18, D_loss 0.315410 acc  59%, (G_loss 6.081370, adv_loss 0.504662, cycle_loss 0.507205) , time 0:28:23.204904\n",
            "Epoch - 0, Batch - 19, D_loss 0.287369 acc  63%, (G_loss 5.477740, adv_loss 0.489427, cycle_loss 0.449889) , time 0:29:49.447701\n",
            "Epoch - 0, Batch - 20, D_loss 0.304744 acc  59%, (G_loss 6.178717, adv_loss 0.482696, cycle_loss 0.521332) , time 0:31:15.166243\n",
            "Epoch - 0, Batch - 21, D_loss 0.226023 acc  70%, (G_loss 6.169075, adv_loss 0.550113, cycle_loss 0.506885) , time 0:32:41.162878\n",
            "Epoch - 0, Batch - 22, D_loss 0.187559 acc  79%, (G_loss 7.088452, adv_loss 0.553034, cycle_loss 0.598238) , time 0:34:07.795229\n",
            "Epoch - 0, Batch - 23, D_loss 0.179552 acc  78%, (G_loss 6.169099, adv_loss 0.597057, cycle_loss 0.497499) , time 0:35:33.669948\n",
            "Epoch - 0, Batch - 24, D_loss 0.140004 acc  83%, (G_loss 5.991792, adv_loss 0.709594, cycle_loss 0.457260) , time 0:36:59.419383\n",
            "Epoch - 0, Batch - 25, D_loss 0.141844 acc  84%, (G_loss 6.658857, adv_loss 0.609052, cycle_loss 0.544075) , time 0:38:24.546227\n",
            "Epoch - 0, Batch - 26, D_loss 0.225622 acc  73%, (G_loss 7.186135, adv_loss 0.563715, cycle_loss 0.605870) , time 0:39:49.981290\n",
            "Epoch - 0, Batch - 27, D_loss 0.183383 acc  77%, (G_loss 6.441431, adv_loss 0.615790, cycle_loss 0.520985) , time 0:41:15.304316\n",
            "Epoch - 0, Batch - 28, D_loss 0.151128 acc  83%, (G_loss 7.053759, adv_loss 0.608049, cycle_loss 0.583766) , time 0:42:41.016417\n",
            "Epoch - 0, Batch - 29, D_loss 0.161375 acc  81%, (G_loss 7.195264, adv_loss 0.664613, cycle_loss 0.586604) , time 0:44:07.151822\n",
            "Epoch - 0, Batch - 30, D_loss 0.175716 acc  80%, (G_loss 5.791803, adv_loss 0.602505, cycle_loss 0.458679) , time 0:45:32.643300\n",
            "Epoch - 0, Batch - 31, D_loss 0.144226 acc  84%, (G_loss 6.567374, adv_loss 0.605137, cycle_loss 0.535710) , time 0:46:58.240043\n",
            "Epoch - 0, Batch - 32, D_loss 0.135053 acc  85%, (G_loss 6.362265, adv_loss 0.675541, cycle_loss 0.501118) , time 0:48:23.392752\n",
            "Epoch - 0, Batch - 33, D_loss 0.162072 acc  81%, (G_loss 6.450615, adv_loss 0.626133, cycle_loss 0.519835) , time 0:49:48.796869\n",
            "Epoch - 0, Batch - 34, D_loss 0.194004 acc  77%, (G_loss 6.253523, adv_loss 0.523637, cycle_loss 0.520625) , time 0:51:14.158815\n",
            "Epoch - 0, Batch - 35, D_loss 0.115076 acc  87%, (G_loss 6.452311, adv_loss 0.706122, cycle_loss 0.504007) , time 0:52:39.619742\n",
            "Epoch - 0, Batch - 36, D_loss 0.109680 acc  90%, (G_loss 6.588009, adv_loss 0.705696, cycle_loss 0.517662) , time 0:54:04.865582\n",
            "Epoch - 0, Batch - 37, D_loss 0.078652 acc  90%, (G_loss 6.289916, adv_loss 0.723046, cycle_loss 0.484382) , time 0:55:30.304552\n",
            "Epoch - 0, Batch - 38, D_loss 0.122781 acc  87%, (G_loss 6.395870, adv_loss 0.650986, cycle_loss 0.509390) , time 0:56:55.579563\n",
            "Epoch - 0, Batch - 39, D_loss 0.164169 acc  82%, (G_loss 5.729369, adv_loss 0.640729, cycle_loss 0.444791) , time 0:58:21.025172\n",
            "Epoch - 0, Batch - 40, D_loss 0.157600 acc  82%, (G_loss 7.185473, adv_loss 0.688289, cycle_loss 0.580890) , time 0:59:46.681574\n",
            "Epoch - 0, Batch - 41, D_loss 0.178808 acc  79%, (G_loss 6.330806, adv_loss 0.692512, cycle_loss 0.494578) , time 1:01:12.028013\n",
            "Epoch - 0, Batch - 42, D_loss 0.118110 acc  86%, (G_loss 6.363087, adv_loss 0.665170, cycle_loss 0.503275) , time 1:02:37.086173\n",
            "Epoch - 0, Batch - 43, D_loss 0.068755 acc  94%, (G_loss 8.338428, adv_loss 0.763192, cycle_loss 0.681204) , time 1:04:03.012794\n",
            "Epoch - 0, Batch - 44, D_loss 0.084909 acc  91%, (G_loss 7.614048, adv_loss 0.750342, cycle_loss 0.611336) , time 1:05:28.697609\n",
            "Epoch - 0, Batch - 45, D_loss 0.104296 acc  89%, (G_loss 6.666302, adv_loss 0.725565, cycle_loss 0.521517) , time 1:06:54.066844\n",
            "Epoch - 0, Batch - 46, D_loss 0.087236 acc  91%, (G_loss 7.214336, adv_loss 0.724417, cycle_loss 0.576550) , time 1:08:19.685597\n",
            "Epoch - 0, Batch - 47, D_loss 0.084483 acc  91%, (G_loss 7.008984, adv_loss 0.762070, cycle_loss 0.548484) , time 1:09:45.111973\n",
            "Epoch - 0, Batch - 48, D_loss 0.086356 acc  92%, (G_loss 6.334752, adv_loss 0.753648, cycle_loss 0.482746) , time 1:11:10.808310\n",
            "Epoch - 0, Batch - 49, D_loss 0.109422 acc  88%, (G_loss 6.577497, adv_loss 0.731680, cycle_loss 0.511414) , time 1:12:36.203282\n",
            "Epoch - 0, Batch - 50, D_loss 0.083503 acc  91%, (G_loss 6.752412, adv_loss 0.754410, cycle_loss 0.524359) , time 1:14:01.609790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch - 0, Batch - 51, D_loss 0.105093 acc  89%, (G_loss 6.386505, adv_loss 0.707376, cycle_loss 0.497175) , time 1:15:47.730100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7UnZEr66dvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cycleGAN2 = cygan(15)\n",
        "cycleGAN2.train(epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMRtFAIX6hQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cycleGAN3 = cygan(1)\n",
        "cycleGAN3.train(epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8mXXIg3I3Vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "!zip -r cycleganimages.zip /content/cycleganimages\n",
        "files.download('cycleganimages.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhiF7JwBhEJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cycleGAN.losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NmbBFj-mB9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}